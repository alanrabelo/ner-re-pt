The data must be converted to the OpenNLP name finder training format. Which is one sentence per line. The sentence must be tokenized and contain spans which mark the entities. Documents are separated by empty lines which trigger the reset of the adaptive feature generators. A training file can contain multiple types. If the training file contains multiple types the created model will also be able to detect these multiple types. For now its recommended to only train single type models, since multi type support is stil experimental.

Sample sentence of the data:

<START:person> Pierre Vinken <END> , 61 years old , will join the board as a nonexecutive director Nov. 29 .
Mr . <START:person> Vinken <END> is chairman of Elsevier N.V. , the Dutch publishing group .

The training data should contain at least 15000 sentences to create a model which performs well. 


-----------------------------------------------------------------------
DEPRECATED
1- Using python script, transform EM tags in START and END tags
2- Remove all \n from input file
3- Perform sentence detector using openNLP SentenceDetector:
	opennlp SentenceDetector pt-sent.bin < input.txt > output.txt
NOTE: output file has UTF-8 encoding!
4- Remove manually all <DOC..>
-----------------------------------------------------------------------

https://opennlp.apache.org/documentation/manual/opennlp.html#tools.namefind.recognition.cmdline

bin/opennlp TokenNameFinderTrainer
Usage: opennlp TokenNameFinderTrainer -lang language -encoding charset [-iterations num] [-cutoff num] [-type type] -data trainingData -model model
-lang language     specifies the language which is being processed.
-encoding charset  specifies the encoding which should be used for reading and writing text.
-iterations num    specified the number of training iterations
-cutoff num        specifies the min number of times a feature must be seen
-type The type of the token name finder model

$bin/opennlp TokenNameFinderTrainer -encoding UTF-8 -lang en -data en-ner-person.train -model en-ner-person.bin


----------------------
Used NLTK for sentence segmentation

join faulty sentences (sentences with <END> tag with no match)
1. match <START> and <END> tags
1. if there is an <END> tag with no match, then join with previous sentence